{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pythag(pf,pa,exp=11.5):\n",
    "    return (pf**exp)/(pa**exp+pf**exp)\n",
    "\n",
    "def pythagGame(df_game,exp=11.5):\n",
    "    p={}\n",
    "    for iteam in np.arange(1,3):\n",
    "        pf = df_game['AdjO_'+str(iteam)]\n",
    "        pa = df_game['AdjD_'+str(iteam)]\n",
    "        p[str(iteam)] = pythag(pf,pa,exp)\n",
    "    \n",
    "    return p['1']*(1.-p['2'])/(p['1']+p['2']-2.*p['1']*p['2'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teamType=pd.read_csv('data/team_type.csv')\n",
    "teamTypeDict={}\n",
    "for r in teamType.values:\n",
    "    teamTypeDict[r[0]]=r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/games/all_games_2017.csv',index_col=0)\n",
    "# df=pd.read_csv('data/games/tourn_games_2016.csv',index_col=0)\n",
    "# y=df['outcome']\n",
    "# dropLabels=['School_1','Conf_1','wpct_1','Rank_1','WL_1','sched_url_1', 'name_1',\\\n",
    "#             'School_2','Conf_2','wpct_2','Rank_2','WL_2','sched_url_2', 'name_2', 'outcome']\n",
    "\n",
    "# y=df['outcome']\n",
    "dropLabels=['School_1','Conf_1','wpct_1','Rank_1','WL_1','sched_url_1', 'wpct_1','TmPts_1', 'OppPts_1',\\\n",
    "            'School_2','Conf_2','wpct_2','Rank_2','WL_2','sched_url_2', 'wpct_2','TmPts_2', 'OppPts_2', 'outcome']\n",
    "# dropLabels.append('round')\n",
    "dfAll=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types=[]\n",
    "for r in df.itertuples():\n",
    "    \n",
    "    t1=teamTypeDict[r.School_1]\n",
    "    t2=teamTypeDict[r.School_2]\n",
    "    \n",
    "    types.append(str(min(t1,t2))+str(max(t1,t2)))\n",
    "    \n",
    "df['types']=types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res=[]\n",
    "dfAll=pd.DataFrame()\n",
    "for year in np.arange(2017,2003,-1):\n",
    "    df=pd.read_csv('data/games/tourn_games_'+str(year)+'.csv',index_col=0)\n",
    "    dfAll=dfAll.append(df,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['School_1', 'wpct_1', 'SRS_1', 'SOS_1', 'TmPts_1', 'OppPts_1', 'Pace_1',\n",
       "       'ORtg_1', 'FTr_1', '3PAr_1', 'TS%_1', 'TRB%_1', 'AST%_1', 'STL%_1',\n",
       "       'BLK%_1', 'eFG%_1', 'TOV%_1', 'ORB%_1', 'FT/FGA_1', 'sched_url_1',\n",
       "       'Rank_1', 'Conf_1', 'WL_1', 'AdjEM_1', 'AdjO_1', 'AdjD_1', 'AdjT_1',\n",
       "       'Luck_1', 'AdjEM.1_1', 'OppO_1', 'OppD_1', 'NCSOS_AdjEM_1', 'name_1',\n",
       "       'School_2', 'wpct_2', 'SRS_2', 'SOS_2', 'TmPts_2', 'OppPts_2', 'Pace_2',\n",
       "       'ORtg_2', 'FTr_2', '3PAr_2', 'TS%_2', 'TRB%_2', 'AST%_2', 'STL%_2',\n",
       "       'BLK%_2', 'eFG%_2', 'TOV%_2', 'ORB%_2', 'FT/FGA_2', 'sched_url_2',\n",
       "       'Rank_2', 'Conf_2', 'WL_2', 'AdjEM_2', 'AdjO_2', 'AdjD_2', 'AdjT_2',\n",
       "       'Luck_2', 'AdjEM.1_2', 'OppO_2', 'OppD_2', 'NCSOS_AdjEM_2', 'name_2',\n",
       "       'outcome', 'round', 'region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropLabels=['School_1','Conf_1','wpct_1','Rank_1','WL_1','sched_url_1', 'name_1', 'wpct_1','TmPts_1', 'OppPts_1',\\\n",
    "            'School_2','Conf_2','wpct_2','Rank_2','WL_2','sched_url_2', 'name_2', 'wpct_2','TmPts_2', 'OppPts_2', 'outcome', 'region']\n",
    "dropLabels.append('round')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on scaled inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.780\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dfClean = dfAll.drop(dropLabels,axis=1).dropna(axis=1)\n",
    "scaler=StandardScaler().fit(dfClean)\n",
    "\n",
    "scaled=scaler.transform(dfClean)\n",
    "\n",
    "\n",
    "X=scaled\n",
    "y=dfAll['outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# model = LogisticRegression(C=0.001,multi_class='multinomial',solver='sag')\n",
    "model = LogisticRegression()\n",
    "# model=RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=0)\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean())) \n",
    "\n",
    "# y_predPythag=pythagGame(X_test)\n",
    "\n",
    "# print('Accuracy using pythagorean win expectation: %.3f' % ((np.round(y_predPythag)==y_test).sum()/len(y_test)))\n",
    "\n",
    "# res.append([year,results.mean(),(np.round(y_predPythag)==y_test).sum()/len(y_test)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on non-scaled inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['School_1', 'wpct_1', 'SRS_1', 'SOS_1', 'TmPts_1', 'OppPts_1', 'Pace_1',\n",
       "       'ORtg_1', 'FTr_1', '3PAr_1', 'TS%_1', 'TRB%_1', 'AST%_1', 'STL%_1',\n",
       "       'BLK%_1', 'eFG%_1', 'TOV%_1', 'ORB%_1', 'FT/FGA_1', 'sched_url_1',\n",
       "       'Rank_1', 'Conf_1', 'WL_1', 'AdjEM_1', 'AdjO_1', 'AdjD_1', 'AdjT_1',\n",
       "       'Luck_1', 'AdjEM.1_1', 'OppO_1', 'OppD_1', 'NCSOS_AdjEM_1', 'name_1',\n",
       "       'School_2', 'wpct_2', 'SRS_2', 'SOS_2', 'TmPts_2', 'OppPts_2', 'Pace_2',\n",
       "       'ORtg_2', 'FTr_2', '3PAr_2', 'TS%_2', 'TRB%_2', 'AST%_2', 'STL%_2',\n",
       "       'BLK%_2', 'eFG%_2', 'TOV%_2', 'ORB%_2', 'FT/FGA_2', 'sched_url_2',\n",
       "       'Rank_2', 'Conf_2', 'WL_2', 'AdjEM_2', 'AdjO_2', 'AdjD_2', 'AdjT_2',\n",
       "       'Luck_2', 'AdjEM.1_2', 'OppO_2', 'OppD_2', 'NCSOS_AdjEM_2', 'name_2',\n",
       "       'outcome', 'round', 'region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropLabels=['outcome', 'region']\n",
    "dropLabels.append('round')\n",
    "for t12 in ['1', '2']:\n",
    "    dropLabels.append('School_'+t12)\n",
    "    dropLabels.append('Conf_'+t12)\n",
    "    dropLabels.append('wpct_'+t12)\n",
    "    dropLabels.append('Rank_'+t12)\n",
    "    dropLabels.append('WL_'+t12)\n",
    "    dropLabels.append('sched_url_'+t12)\n",
    "    dropLabels.append('name_'+t12)\n",
    "    dropLabels.append('TmPts_'+t12)\n",
    "    dropLabels.append('OppPts_'+t12)\n",
    "    dropLabels.append('SRS_'+t12)\n",
    "    dropLabels.append('SOS_'+t12)\n",
    "    dropLabels.append('AdjO_'+t12)\n",
    "    dropLabels.append('AdjD_'+t12)\n",
    "    dropLabels.append('AdjT_'+t12)\n",
    "    dropLabels.append('Luck_'+t12)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FTr_1', '3PAr_1', 'TS%_1', 'TRB%_1', 'AST%_1', 'BLK%_1', 'eFG%_1',\n",
       "       'TOV%_1', 'FT/FGA_1', 'AdjEM_1', 'AdjEM.1_1', 'OppO_1', 'OppD_1',\n",
       "       'NCSOS_AdjEM_1', 'FTr_2', '3PAr_2', 'TS%_2', 'TRB%_2', 'AST%_2',\n",
       "       'BLK%_2', 'eFG%_2', 'TOV%_2', 'FT/FGA_2', 'AdjEM_2', 'AdjEM.1_2',\n",
       "       'OppO_2', 'OppD_2', 'NCSOS_AdjEM_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=dfAll.drop(dropLabels,axis=1).dropna(axis=1)\n",
    "X.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.768\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "test_size = 0.3\n",
    "\n",
    "\n",
    "X=dfAll.drop(dropLabels,axis=1).dropna(axis=1)\n",
    "y=dfAll['outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "\n",
    "# model = LogisticRegression(C=0.001,multi_class='multinomial',solver='sag')\n",
    "model = LogisticRegression(C=1,penalty='l2')\n",
    "# model=RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "kfold = model_selection.KFold(n_splits=n_fold, random_state=0)\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean())) \n",
    "\n",
    "# y_predPythag=pythagGame(X_test)\n",
    "\n",
    "# print('Accuracy using pythagorean win expectation: %.3f' % ((np.round(y_predPythag)==y_test).sum()/len(y_test)))\n",
    "\n",
    "# res.append([year,results.mean(),(np.round(y_predPythag)==y_test).sum()/len(y_test)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write model to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres://gshau@localhost/ncaabb\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "dbname = 'ncaabb'\n",
    "username = 'gshau' # change this to your username\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "print(engine.url)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs=pd.DataFrame(np.array((X_train.keys(),model.coef_[0])).T,columns=['Property','coef_'])\n",
    "coefs.to_sql('tourney_fit', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38072274, -0.28572126, -0.11168409, -0.17369718, -0.10186226,\n",
       "         0.05378959, -0.04957427, -0.04668042, -0.07612363, -0.06950065,\n",
       "        -0.11168409,  0.36900107,  0.11268003, -0.08300416,  0.07224561,\n",
       "         1.102244  ,  0.27078436,  0.14377164, -0.15429889, -0.0061403 ,\n",
       "         0.50413497, -0.04508178, -0.12690649,  0.03024592, -0.03061636,\n",
       "         0.0054054 ,  0.00953418, -0.01104222, -0.0142538 ,  0.04171306,\n",
       "        -0.12690649, -0.23952509, -0.30277646,  0.37034542, -0.07609814,\n",
       "        -1.04638202, -0.02455535, -0.0550908 , -0.02879727, -0.00368181]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_\n",
    "# model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAFFCAYAAAAEpe2sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1m8McpwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a140b58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndata=int(len(model.coef_[0])/2)\n",
    "plt.bar(np.arange(ndata)-0.15, model.coef_[0][:ndata],width=0.3)\n",
    "plt.bar(np.arange(ndata)+.15, -model.coef_[0][ndata:],width=0.3)\n",
    "labels=dfClean.keys();\n",
    "plt.xticks(np.arange(ndata), labels, rotation='vertical');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show logistic regression plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return 1./(1.+np.exp(-x))\n",
    "# logit(X_test.dot(model.coef_.T)).values-model.predict_proba(X_test)[:,1,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAESCAYAAAASQMmzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcHFW5//HPM1syM8lkh4QkEJYg\nREAiwy64oQKyKKiIwlURUREFFBXhuiGyCFxEjSJcQUQRkEWCXgV+7Cogk7BvEkIIIYHs6+wz5/fH\nOWeq0pktS091T3/fr9e8errqVNVT61OnTnWVOecQEREBKMs6ABERKRxKCiIi0kVJQUREuigpiIhI\nFyUFERHpoqQgIiJdlBRERKSLkoKIiHRRUhARkS4VWQewscaOHeumTJmSdRgiIkVl1qxZS51z4/oq\nV3RJYcqUKTQ0NGQdhohIUTGz1/pTTpePRESki5KCiIh0UVIQEZEuSgoiItJFSUFERLooKYiISBcl\nBRER6aKkICIiXfL24zUzuwY4AljsnNutm/4GXAEcDjQCn3XOzc5XPEWvDb+U2vFrrQao7KFsI7AU\naAGGAGND+b7GvwpYHj47QvcKYDgwBhiRGn8TsC6UqwxlRuTElI7Zhf9XAGtDbGWh+1CgLkzLwmdd\niLkRWB26D091Wx7G1RimOSxMvzX0awQ6wzDlQHOYZmdYJquAJaFsW1hGU8JfRZi/xjBcc5jP8hDr\nWmBemP4wYJtQ5o0wzEhgQoh1RBh2GbA4zMuIMMyoEO+aMA/jw3w3hmVrQC1QHWJsDp9VYZxvAf8J\n464M81CR+n/bMJ3qsD7eBF4Oww0LMY4K81QW4q0KMTWG5dUSYpmD36aGAZPDMEvD/MTlXxvGVxaG\n6cRvN9uHeW4Lw8wLMTSHeIcB41LLY11Y1sPx287SsK7WhmUyKpSPyytu20vDeDtCmfEhtlVhGTWH\nZTE8dG8n2YbbUst2aCgXp90S4qkO/eP22dv23ts+Gss1hfmN4yTMn2P99V0eyrjwWR3G25Yzjupe\npgkYZt33ySnnnOtPuY1mZgfjV+PvekgKhwNfxSeFfYErnHP79jXe+vp6V3K/aI4H7Ar8BtKB3/By\nN0rwG9vr+ANf3MFb8DtyT4kh7qyr8DvJKvzO7sI06vA7btzgKkgO7uWhf2foP5Zkg40xd+IPmIvC\neJaG4TvDsGVhmHgwiweHJvyGXhviXIffUcrD/0tCjIR5bcbvVJ0kByYXPuvCcisDXgmfy0iSWk0o\nMzosq7hjLg3LujKUXQksCMMPD2VeDMt7YiizIoxvWhjP4hBTS+gfd+DV+AP31mE868LyLsMnltYw\n3Dr8AW4V/oC1MsT+YhhXe+i2IoxvuxDPUGBP/AF0LkkiHUKS1LcCdg/jaA/fF4e4DVgIPBFiqgtl\nXg3zPjHEtyjEPT6sm+Uhjomp9bUrftucF/qvC9PpCPGNDvMwBpgUhnuFZPuJ2+fIEMuoUG77EGc8\nUagO02vKWUfxwB4TXe7Jwrowrdow783hMy6H1rC+JoZl5Oh5e+9tH43lHEmSayPZDoeFdbQmDBuT\nM2HZVODX+ZowDy1hHITYrZtphulWVlU+2ebaptOHvF0+cs49hF9NPTkanzCcc+5RYKSZTchXPEWt\nkWRjI3xWhO65lpIkBMLnkNC9t/G34jfMDvyGVRamEw+yHfiNOSaZNpIzpxbWP8PMjTme+Q7DH8xc\niCnuOOX4HS7uTDGWRpIz9NhvXeqvlmQLbsPvKPEssxl/EFsW4m8M87KS9RNCPAOMO+YK/MGKEFNF\navwd+LPteEZZEZZJe5heYxjfkDAPS/Bnrp1hXG34HZswnqEhDvA7sQvdy8PwsVZSjj/wxjjbgNdS\n06lMfcY4LAy/IAzbTFKzGUZyBmr4A3U8y5xDcvKwBr/duFC2NhXPapKDW21qfb2V+t4apmX4Gsqq\nEEdZmH5lmG4HSSJqJTmTrgrDrAnxDA/Dx2W1Dr8+W8N04/YY1+k6kppDFUkNy0K/1aFc3GaHhW6E\n6SwP89KJTzJ1Ybh4Zt7T9g4976OxXAvJAT5u71Uk22V1mLchYbhOkn0ldl+ZGkd5apzdHRcawdG/\nCkCWbQoT8ee00YLQbQNmdoqZNZhZw5IlSwYkuIISN4a08tA9VzxAp8UDd2/jdzl/ZSSXd+JfW/iM\n5ePBOsYX++XG3B6GHUpy5liG3znj2Xt7anq58USOZOeIZ1aE4TpSw5aFcvEMLn7GHaYKv5PHnThe\ntorTa2L9nSwdR7zsFeNvJtlxY9yVJImplSShWapfYxiuJTX+eNkqfZCPyaExfLaRnBkPTZVrD9/b\nw7yTms+YrOLlxCiun5hIq8L/cfvpSC0DS81TrJ20hWnFSxsdqeURax6xFriWZNuI6ysu/3hmHpd1\ne5ivuHzicDUk67EzNVz8TG/35Tn947zGbTvGF9dNXKdxO3Ksv113huXbQd/bezqG3H20nfX3mRhT\njDHGG5NFLFOWGibu482p/ulxtnTA6tWwaBHMmQMtLTGOfmWFLB+I1931rW6Dds5dBVwF/vJRPoMq\nSBUkZ7VR3KlyxbPH9A4Sd7Dexm85f/HAku5WSXJwiAf0dHyxPSA35nidu5lkx4o7dXn4P+7oljO+\n9FaSrsGU4w8QhOFiTHF86bPReGbfjj+wrCC5Zhx3pniZwEjOXuPBLcYQazhNqfiH4msE6eQSaxVx\nXuNycKl+NSQH6Tj+dpLawJBU3M2hfPosOX6vIjlQxmvm8VQvnqnHeY4H2bgtxPUXz+w7wv+toXus\n9cSDe5yn5STrtCyUj8t+aJhGNck6bQtxxG0jrq+mMFy8jh+XdfoSSTrW2H7UnlpuQ1Of6e2+I6d/\nXAfx/4pUubjNpLej3O2wjOQg3Nf2TmrcuftoRap7OqaumJthyXJYtQIWr4CnV8CUfWDU1jD3WfjZ\ntbB8NTSvhlWroWk1XPQreNsecOcN8K3PQ3Pz+tN8+mnYdndYf2/qUZZJYQH+6m00CX8FU3LV4KvR\nsOH1ylxjSepfuW0KvY0/nk2mz4zStYbY8BfbFOLZX2xTaA3jqUmNc1Xq/1r8ZYwxrN94F3eOeM0/\nnrHG8cX5jfNeS7LjpdsUYmN33OmH4i8FjMGf/daE7iPxVfQxJFX1ptS0RpFcM64juewW2xTG47fc\nmGhHhPkakppGS/h/HEmbQl3ovizM33iSNgVIagDjSS4lNOMPpuvwjcKxTaES324Q2xRi8lgX+teQ\nnCXvEuJoCvO2giRZtoZyU0L/dmAnkstnw0m2p3jpblhY7rGhNbZ5jAjTHY5PGmNCTHEbmUpyo0E8\nuMcEOYykTaGKpI1nUWoaLfgkMTK1rGrDd8O3y8SL1THh1LJhm0I8CRiWKlcT5mFtmK+Y7IeE7mUk\nbUATWX/77G57T++jdQ7a2qGyElasgD//BeYtgsVvweKlsHwJfObrsN8h8OD9cOL72MBP/gwHHw1L\nXocbroLhdVA9HEbUQU0dtHb66U3bBU7+KoyqhbpaGDYMamth4kSoAetfTshfQzOAmU0B/tJDQ/OH\ngdNIGpp/5pzbp69xlmRDM+juI919pLuPCvHuo+Y10N4Oo0bB0lVw4cXw2muwcD4sfN1fwrn4Yjjj\nDHjpJdhlFx9rTQ2MHgejxsJZ34fDj4RFb8BN18HI0TBsFNSMgtrRsONUGDNis+8+KrOy2Z2uc6/u\n+ybyeffRH4H34DfPt4DvE8J1zl0Zbkn9BXAofhP8nHOuz6N9ySYFEclGZyeUlUFHB1x0Ebz8sr9W\n//LLsHgxfOMbcOmlsG6dTw6TJsF22/nPbbaBI4+Ed70L2tpg3jyYMMGfxQ8wM5vlnKvvs1w+awr5\noKQgInnz3HP+Gvwzz8Czz/rP/feHG27w/ceNg6oqmDoVdtrJ/x18MBxwgO/f0QHluS3OhaG/SaHo\n3rwmIrLZ2tv9Qf/xx/2dOt/4hu9+wgnw5JNQUQFvexvsuy+8L3Wdf8ECGNLLXRsFmhA2hpKCiJSO\nq66C3/0OZs+Gpibfbfvt4etfBzP45S9h+HDYeWdfI8jVW0IYJJQURGTwWb4cHnoIHngAHn7Y/19b\nC0uWgHPwxS/CPvvA3nvDjjvS9QSI/ffPNOxCoKQgIoPHAw/4s/4nn/QH/+pqOPBAnwxqa+Hcc/2f\n9EhPSRWR4tTYCDNnwsknw913+26jR/s7e374Q19DWLEC7rkHpkzJNNRiopqCiBSP9na47Tb4wx98\nImhuhro6qA831eyxh79UJJtMSUFECltnJ7z6qr/2X1YGZ53lu51yChx1FBx0UPeNwrJJlBREpDC9\n+CL89re+VtDaCm+84W8VffBB2HbbQXH7ZyFSUhCRwvLvf8N//7dvCygvh0MPhRNP9A3H4G8hlbxR\nUhCR7K1c6WsDW23lG5Cffx5+/GPfiLzVVllHV1J095GIZGfOHDj1VP8kz/PP993e/W7fhnDOOUoI\nGVBNQUQG3ty58KMfwfXX+3aCT30KTjrJ9zPzj5qWTCgpiMjAO/98uPFG+OpX4dvfhvHjs45IAl0+\nEpH8mz/fP1pi1iz//fzzfW3h8suVEAqMkoKI5M/atXD22f5R07/9bZIUttnGv1dACo6Sgojkx5/+\n5B8/ffHFcPzx/qU0p5ySdVTSB7UpiEh+PPecrw3ccouePlpEVFMQkS1jxQr42tfgzjv993POgcce\nU0IoMkoKIrL57rjDv5R+xgx46infrapKj6IoQrp8JCKbbvVqOOMMuPZa2HNP+PvfYfr0rKOSzaCa\ngohsujvugOuu8y+ueewxJYRBQDUFEdk4zc3+zWb77edfdP/Od8Lb3551VLKFqKYgIv03ezbstRd8\n8IO+YdlMCWGQUVIQkf75zW/8nUSrVvnbTEeNyjoiyQMlBRHpXWcnfOlL/jHWBx/sLx198INZRyV5\noqQgIr0rK/O3ln772/7uorFjs45I8kgNzSLSvYcfhro6eMc74Be/8O0HMuippiAi63MOfv5zeN/7\nfO0AlBBKiJKCiCTa2/0jrr/2NTjsMLjppqwjkgGW16RgZoea2UtmNsfMzu6m/7Zmdr+ZPWFmT5vZ\n4fmMR0R60dQExx4LV1/tn1v05z/DiBFZRyUDLG9JwczKgRnAYcA04Hgzm5ZT7L+Bm51z04FPAr/M\nVzwi0oeyMp8YZsyAH//Yf5eSk8+G5n2AOc65uQBmdiNwNPB8qowD6sL/I4CFeYxHRLrz+utQUwNj\nxvi7i5QMSlo+1/5E4PXU9wWhW9oPgBPMbAHwf8BX8xiPiOR69ln/g7QTTvDflRBKXj63gO5uV3A5\n348HfuucmwQcDlxvZhvEZGanmFmDmTUsWbIkD6GKlKB//AMOOsjfbXTxxVlHIwUin0lhATA59X0S\nG14e+jxwM4Bz7hFgKLDBL2Occ1c55+qdc/Xjxo3LU7giJeRvf4MPfAC23hr+9S/YY4+sI5ICkc+k\n8Dgw1cy2N7MqfEPyzJwy84H3A5jZrvikoKqASD61t8OZZ8K0ab62sN12WUckBSRvDc3OuXYzOw24\nCygHrnHOPWdm5wENzrmZwDeAq83sTPylpc8653IvMYnIllRRAXffDcOGwejRWUcjBcaK7RhcX1/v\nGhoasg5DpPjce6//7cEVV6hBuQSZ2SznXH1f5fTsI5FScP/9cOSRsNNO/hWaI0dmHZEUKJ0uiAx2\nDz4IRxwBO+zgawtKCNILJQWRwezhh+HDH/aNyffeC7p7T/qgpCAymDU1wc47w333+dtPRfqgpCAy\nGLW0+M8PfhAaGmD8+GzjkaKhpCAy2CxZAnvuCddc47/rTiPZCNpaRAaTdet8G8K8ebDLLllHI0VI\nt6SKDBbt7fCJT8CsWXDbbXDAAVlHJEVISUFkMHDOvzHt//4PrrwSjj4664ikSOnykchg8ba3wXe/\n65ODyCZSTUGk2K1ZA8OHw7e+lXUkMgiopiBSzO67z/9S+Yknso5EBgklBZFiNXcufPzjsNVWsOOO\nWUcjg4SSgkgxWrMGjjrKNzDPnAl1dX0PI9IPalMQKTadnf6dyi++CHfdpVqCbFGqKYgUm7Y2/4Kc\nyy+H978/62hkkFFNQaSYOAdDhsDvf591JDJIqaYgUixmz4b6enjlFTDzfyJbmGoKIsXgrbf8r5TN\n/G8SRPJESUGk0MVnGi1fDv/8p78FVSRPlBRECt2558JDD/l2hD33zDoaGeTUpiBSyFpa4P774Utf\ngk9/OutopASopiBSyIYM8e9ZFhkgqimIFKLmZv+Au5UrfWIYMiTriKREKCmIFKIzzoBLLoFHHsk6\nEikxSgoiheb66+HXv4ZvfxsOOyzraKTEKCmIFJJnn/WNygcfDOefn3U0UoKUFEQKyWmn+R+n3Xgj\nVOg+EBl42upECskNN8Abb8CECVlHIiUqrzUFMzvUzF4yszlmdnYPZT5hZs+b2XNmdkM+4xEpWE8/\nDR0dsM02sPfeWUcjJSxvScHMyoEZwGHANOB4M5uWU2Yq8B3gQOfc24Ez8hWPSMF6+WU48EA4u9vz\nJpEBlc+awj7AHOfcXOdcK3AjcHROmS8AM5xzKwCcc4vzGI9I4WltheOPh6oqOP30rKMR6V9SMLMa\nM/uumV0dvk81syP6GGwi8Hrq+4LQLW1nYGcz+6eZPWpmh/Y3cJFB4ZxzYNYs+M1vYNKkrKMR6XdN\n4VqgBdg/fF8A9HW/XHcPe3c53yuAqcB7gOOB/zWzkRuMyOwUM2sws4YlS5b0M2SRAvf3v8Nll8Gp\np8JHPpJ1NCJA/5PCjs65nwBtAM65Jro/6KctACanvk8CFnZT5g7nXJtz7lXgJXySWI9z7irnXL1z\nrn7cuHH9DFmkwI0aBUceCZdemnUkIl36mxRazayacKZvZjviaw69eRyYambbm1kV8ElgZk6ZPwPv\nDeMci7+cNLefMYkUt333hZkzobo660hEuvQ3KXwf+Dsw2cz+ANwLfKu3AZxz7cBpwF3AC8DNzrnn\nzOw8MzsqFLsLWGZmzwP3A990zi3bhPkQKR6XXAJnnulfniNSYMy53Mv8PRQ0GwPsh79s9Khzbmk+\nA+tJfX29a2hoyGLSIpuvoQH239+3Idx8s96zLAPGzGY55+r7Krcxt6ROBMqBKuBgMztmU4MTKUnr\n1vkX5YwfD1ddpYQgBalfj7kws2uAPYDngM7Q2QG35SkukcHn61/3P1S7917fyCxSgPr77KP9nHPT\n+i4mIt16/XX/SOyzzoL3vjfraER61N+k8IiZTXPOPZ/XaEQGq8mT4cknYbvtso5EpFf9bVO4Dp8Y\nXjKzp83sGTN7Op+BiQwKzsE99/jPnXfWazWl4PW3pnANcCLwDEmbgoj0ZcYM+OpX4W9/g0P1FBcp\nfP1NCvOdc7k/PBOR3jz/PHzzm3D44fChD2UdjUi/9DcpvBjedXAnqV8yO+d095FId1pa/O2nw4fD\nNdfo9lMpGv1NCtX4ZPDBVDfdkirSk+9+1zcsz5wJW2+ddTQi/davpOCc+1y+AxEZVPbf378058gj\ns45EZKP0930Kk8zsdjNbbGZvmdmtZqaHv4v05KMfhQsvzDoKkY22Me9TmAlsg3/cxZ2hm4iknXwy\n/PSnWUchssn6mxTGOeeudc61h7/fAnqxgUjaTTf5N6itXp11JCKbrL9JYamZnWBm5eHvBECPuBaJ\nFiyAL30J9tvPv2JTpEj1NymcBHwCeBNYBHwsdBORzk747Gehrc0/36iivzf1iRSe/t59NB84qs+C\nIqXo0Ufhvvvg17+GnXbKOhqRzdLfu4+uM7ORqe+jwuO0ReSAA+Cpp3wjs0iR6+/loz2ccyvjF+fc\nCmB6fkISKRKtrfCvf/n/d99dv1qWQaG/SaHMzLreCmJmo+n/r6FFBqfvfhfe9S544YWsIxHZYvp7\nYL8M+JeZ3YJ/vMUngAvyFpVIoXvgAbjkEn/JaNdds45GZIvpb0Pz78ysAXgfYMAxeuGOlKwVK+C/\n/ss3Kl9+edbRiGxR/X1H8/XOuROB57vpJlI6nINTT4VFi3x7Qm1t1hGJbFH9vXz09vQXMysH9try\n4YgUgQMOgHe+E/beO+tIRLa4XpOCmX0HOAeoNrPV+EtHAK3AVXmOTaTwmPk3qYkMUr3efeScu9A5\nNxy4xDlX55wbHv7GOOe+M0AximSvowOOOgpuuSXrSETyqr+Xj/5mZgfndnTOPbSF4xEpTBddBHfe\nCR//eNaRiORVf5PCN1P/DwX2AWbh70YSGdwefxx+8AM47jg44YSsoxHJq/7ekrre66PMbDLwk7xE\nJFJI1q7171qeMAF+9Sv9alkGvU39VfICYLctGYhIQbr1Vpgzxz/wbtSovsuLFLn+/k7h5/hfMoNv\nnJ4OPJWvoEQKxmc+A9Onwx57ZB2JyIDo77OPngf+A7wEPAp8yznX58VVMzvUzF4yszlmdnYv5T5m\nZs7M6vsZj0h+zZsHzzzj/1dCkBLS1+8UKvDPODoJmI//ncJk4Boz+7dzrq2XYcuBGcAH8JebHjez\nmbmPxzCz4cDXgMc2Z0ZEtpi2Njj+eHj1Vf9XXZ11RCIDpq+awiXAaGB759w7nXPTgR2AkcClfQy7\nDzDHOTfXOdcK3Agc3U25H+EbrZs3KnKRfPnBD/yLc664QglBSk5fSeEI4AvOuTWxg3NuNfBl4PA+\nhp0IvJ76viB062Jm04HJzrm/9DYiMzvFzBrMrGHJkiV9TFZkM9x3H1x4IXz+8/4WVJES01dScM45\n103HDpKG5550d+9e1zBmVgZcDnyjryCdc1c55+qdc/Xjxo3rq7jIplm61P8OYeedfS1BpAT1lRSe\nN7P/yu1oZicAL/Yx7AJ8+0M0CViY+j4cf1vrA2Y2D9gPmKnGZslMXR2ceCLceKOefiolq69bUr8C\n3GZmJ+F/weyAvYFq4KN9DPs4MNXMtgfeAD4JfCr2dM6tAsbG72b2AHCWc65hI+dBZPO1t0NVFVx8\ncdaRiGSqrwfiveGc2xc4D5iHvwPpPOfcPs65N/oYth04DbgLeAG42Tn3nJmdZ2ZHbZHoRbaE2bP9\n29Oe0k9vRKybJoOCVl9f7xoaVJmQLWTFCthrL38b6hNPwNixfQ8jUoTMbJZzrs/L85v6mAuR4tfZ\n6X+x/Prr8PDDSggiKClIKbv0Uv847CuugP32yzoakYLQ38dciAwunZ3w4IP+/Qh6k5pIF9UUpDSV\nlcHMmdDSosdhi6SopiClpb0dzjoL3ngDysuhpibriEQKipKClJbvfx8uuwweeCDrSEQKkpKClI6/\n/hUuuAC+8AX/NjUR2YCSgpSGOXP8IyymT4ef/SzraEQKlpKClIZvftM3Lt96KwwdmnU0IgVLdx9J\nabj2WnjlFdh++6wjESloqinI4HbLLdDcDCNH+sdZiEivlBRk8LrhBv/jNLUhiPSbkoIMTg0N/u1p\nBx8MZ5yRdTQiRUNJQQafRYvgIx+Brbf2l4+qqrKOSKRoqKFZBp+TToKVK+Ff/wK9vlVkoygpyODz\n05/C3Lmwxx5ZRyJSdHT5SAaPe+8F5+Btb4PDDss6GpGipKQgg8PPfw6HHAJ//GPWkYgUNSUFKX63\n3gqnnw5HHw3HHZd1NCJFTUlBitvDD/uH2+23n/9dQnl51hGJFDUlBSlea9fCMcfAlCn+tZp6N4LI\nZtPdR1K8hg2D66+HXXaBMWOyjkZkUFBNQYrPypVw113+/0MP9TUFEdkilBSkuKxe7W83/chH4M03\ns45GZNDR5SMpHmvW+ITQ0AB/+hOMH591RCKDjpKCFIe1a+Hww+Gxx+Cmm3xNQUS2OF0+kuLwxz/C\nI4/4z2OPzToakUFLNQUpDiefDPvuq+cZieSZagpSuBob4fjj4dlnwUwJQWQA5DUpmNmhZvaSmc0x\ns7O76f91M3vezJ42s3vNbLt8xiNFpLHRP7bippvgmWeyjkakZOQtKZhZOTADOAyYBhxvZtNyij0B\n1Dvn9gBuAX6Sr3ikiCxb5h9ud++9cO21vrYgIgMinzWFfYA5zrm5zrlW4Ebg6HQB59z9zrnG8PVR\nYFIe45FisGgRHHQQzJ7tbzv9zGeyjkikpOQzKUwEXk99XxC69eTzwN/yGI8Ug1Gj/PsQ7rpLdxmJ\nZCCfdx9ZN91ctwXNTgDqgXf30P8U4BSAbbfddkvFJ4XkkUd8Mhg9Gm6/PetoREpWPmsKC4DJqe+T\ngIW5hczsEOBc4CjnXEt3I3LOXeWcq3fO1Y/TO3cHn9tvh/e+F848M+tIREpePpPC48BUM9vezKqA\nTwIz0wXMbDrwa3xCWJzHWKRQXXklfOxjsOeecNllWUcjUvLylhScc+3AacBdwAvAzc6558zsPDM7\nKhS7BBgG/MnMnjSzmT2MTgab1lY49VT48pf984zuvRfGjs06KpGSZ851e5m/YNXX17uGhoasw5DN\ntXw51Nf7WsIFF0CFflwvkk9mNss5V99XOe2JMrBmz4bddvMNyk8+CXV1WUckIil6zIUMDOdgxgz/\n/KILL/TdlBBECo5qCpJ/TU2+7eC66+CII+D007OOSER6oJqC5NcLL8D++/uE8P3vwx13wMiRWUcl\nIj1QTUHyb+VK+Otf/UtyRKSgqaYgW97cufDjH/v/d90VXn5ZCUGkSCgpyJbjHFx9tX/vwSWXwPz5\nvntlZbZxiUi/KSnIlrFwoW9EPuUU2G8//w4EPadKpOioTUE2X0eHf9z1woXws5/BV74CZTrfEClG\nSgqy6R58EA480P8a+corYYcdYMcds45KRDaDTudk482bB8ccA+95D/zud77bBz6ghCAyCKimIP23\nbh1ceilcdJG/PHTBBfDpT2cdlYhsQUoK0n/HHuvfiHbccf7uosmT+x5GRIqKLh9Jz5qa4Ior/BNN\nAb73PfjnP+HGG5UQRAYp1RRkQ83NcNVV/jLRokVQUwNf+AIccEDWkYlInqmmIAnn/BNMd9jBP7Ru\n6lR44AGfEESkJCgpCMyZ4z/N4NFHYffd/ZvQHngA3v3uTEMTkYGly0elqq0Nbr0Vfv5zeOQR/3yi\nHXeEP/0Jqqqyjk5EMqKaQql580044wyYNAmOPx4WL4bLL4ettvL9lRBESppqCqVg3jxYsQKmT/e/\nPv7Nb+BDH4KTToJDD9UjKUQmf0IpAAAROklEQVSki5LCYDVvHtx5J9x8M/zjH3Dwwf6xFGPH+tpB\ndXXWEYpIAVJSGCyc8w3F4GsA117r/582zf/y+FOfSsoqIYhID5QUitmiRf7s/5574O67/eOqR46E\nww6D3XaDI4/0t5WKiPSTkkIxibWBBx+EL34RXnrJdx8xwieCVat8Uvj4x7ONU0SKlpJCoWpthaef\nhn//2/899hicey6ccAJsvbW/ffTkk/2TSqdPh/LyrCMWkUFASaEQNDbC88/711a+4x3+WUMTJvjE\nAP520b339o3EALvsAn/9a3bxisigpaQwkNrb/S2h4Bt/H38cnn0WXnnFXxr6xCfgpptg9GhfK5g2\nDfbZxz98LjYii4jkkZJCvtx/vz/ov/yyf4zEyy/Ddtv5p4wC/PnPsGYN7LmnvyS0227+MlD0ve9l\nE7eIlDQlhf7q6IBly5Jf/t53n388xPz58Npr/rOjI2n8/elPYeZMGDcOdtoJ3v/+9Q/6jz6qH42J\nSMHJa1Iws0OBK4By4H+dcxfl9B8C/A7YC1gGHOecm5fPmLo0Nfkfca1YAStX+gP+0qXw2c/CkCHw\n+9/D9dfDkiX+0RCLF0Nnp7/OX1Hhnxv0y1/6JLHttrDrrjBlSnKH0IwZcN11/m6g7ighiEgByltS\nMLNyYAbwAWAB8LiZzXTOPZ8q9nlghXNuJzP7JHAxcFyvI+50/nPpUn89fu1a/5rItWth9To4/OMw\nYgL842G46WpoXA1rV8Pq1f6Wzd/dBdvtAL+cARd9c8Px73c4TJwMb6yBJatgzDbw9ukwaYL/6+jw\nSeHCC+Gyy6B8KDQC7fil2Q5U4p8tBNAGrALWhP9bgHXhsxaYCNSEMmtD96owjorQzwFNQDPQCYwA\n6kK/NuBNYAU+9W4NhPZoGoHVwCJgcfjfhemOBcaFaawNcQ8L35fjU3TsXg2MB7YNw1WGeOeGsmVh\n2BZgafhsBzpC9+Fh/t8K/eK4asK8Dkn93xri7gxll4f5WxPmbWoYnrBMFgHzU8ugM4yjKpSbBIwC\nLCyrSmBo6N8Y1kVniHFomM6bYRw1YZmuCctvXZifsWGc5WGZxjhWhnFMCvP0RhhmFLBdWG9NJNvK\n0LBs418bMAeYF8ZbCWwTplkZ5rk6rL9K/PawJszbsDCduG4aU/MwChgd/o/bhIV5jt2Wh8+43TWF\ncbeEv+FhHONDmTgPNanYYMPtvTzEWx3KEvovC2XaQ7fysHxGh8/0OLvTSLKtDcGvk5oeyrax/j6a\nG7OsJ581hX2AOc65uQBmdiNwNJBOCkcDPwj/3wL8wszMOed6HOvK1X4lP/SQfz1krh33hD0mwJLF\n8Ng/YHgd1NTBmPEwaSp0lMNCYPcPwfdGwbhRUD4KJoyG7cdB9dZ+Y/vol+G4L/tx1uJ3ovTGWleX\n7AAV+INMR/gey7Xhx9WIP3AuB14L/bbG73gvhHGPx+/kq8Nww8M416SGrwqfi/E7Udy5HH5D78Cn\n30aSZDI/dFsevi/HHyRawnia8QfaIfgD0vIQ/0pgSYhta/xBryXEVgO8iN/JavDLsyEsp1r8wXBl\nah7/EcpuF5bdc8CrwO7AVvjksyz8vzgsz0rgafwBejj+oPJmiHchsENYtk+E+V0GvB6WXx3JAX4B\nPvHWASNDPHVh3qrD/A0N894Z4h4Wur8ayo0I420P87ckLOuxYZ08G6Y1LiyjZ8Ny2jn0n49PoBPD\nuCrC8IRlVBXWzbww/x34ZNIY5ml8iGf7MM/pu48tzMfasHzidtIS+q0N446JOiYVwriaw/g6Q7mF\nJAfQ6jD92tCvLHyfhj9497W9N4UyHWEajSQH6LVhma4KcdaFYTpDmXjy0Z24XIaE2FrD98lsmBj6\n2kdlA/lMChPxqypaAOzbUxnnXLuZrQLG4Det7lVX+43ioIN8Y25tLQwbBh21UFMLZSP8Bnj0sXDE\nsX5njWdDw/E72wpgp91h+u5JfyPZwVaTnOV24HeoYWEcI1KxNOKXYNxJy1PdR5CcrVWF6a4jORPr\nCNONB6c1JGfxq0LZEWHpDA/jbcMf2FrxB6+OMI3RYdpx+m+FJRun2RliWBWGJ0yvMyzttfgdsi10\ni8lgaGq6ZfgDyCr8QZ8Qa9zRK8NyA39AiTG/RnI2uAq/4zaSHBiqSc5Y5+APgOXAy2GYijD+cWEa\ny/HrYhH+IFiNX59rwnAxztGhWyU+YQzBr8fqsHwqSGof8cC4MMxzRSrGIfgtd1SIc3noVklygG4l\nSSTrwveOsDzi/KwL0x0Rlocj2dbGhnHFhBhrix0hxmX4mlVM2E1hPcWTiXWsvw2NCP3KQ/d1YVl2\nhPGWp76vIzlLj+Xi+N4iqaV0hOU8Miz30fS9vccH7sYaclwm8eBvqXEYSQJpZcN9LW0pfh3E8Vel\num+bU7avfVQ2kM8L293dQ5lbA+hPGczsFDNrMLOGJWtW+Z1q3Dj/w6299/bX8ydsC+PGABXrbwDN\n+I0m7vjt+Ll2JDt0PFNrCd1cKoo4TPxMi93T0uXizh+7xZ2yLBVHPItqTQ2f2z2upRhTPBNMj59U\nv+bU/MTh4qWt+NijDvzOOiR8xpgrU8PHRNOZiqEdfzCvDP06QtnK1DiN5CysKZSLMZeFPyM5UDjW\nP5DEg6ix/mlLjNXCeJvCdBzJQSYeTKtILhfE6bbhD/prw7haw/DxM8Yal097KBe7Dw3TSa+buM3E\n4TrDX3lqurF/XK5xPVaQrN+m1Hg7SA5kFSTbcDzAtaWmU5laP+2p+OI2nl4v6WmT+h634zj9mOSb\nSM68Y/zxRIBU95629zjfLtUvHUesfZTldHNsuK+lxaSZFrevXH3to7KBfCaFBfjzwmgS/lys2zJm\nVoHP3ctzR+Scu8o5V++cqx83Zlz39Zt49p2umnfgd+TW8Bn7xwNIPHi0hu9DQrdYayBnnLnTTU+L\nnPKxv7H+Tt4aph/jiDtjVWr43O6doV+MqTXEmh4/qX5DU/MTh4sHyKbQrRy/47eQ1F4gOXCmz9zi\nmV2cp2GhXDyIxOv1cZxx5wefhOLZ3xCSg5kL3+PwrSSXAjpILlmkd94YazzLjtfhjeTA0ppazjER\nxunGhBfbP6rC8PEzxhqXT0wosXszyUE+rpu4zcTh4kGuIzXd2D8u17ge20nWbzXrH5jjSUQ7yTZc\nQ9JmFacTa3Fxm4rxxW08vV7S0yb1PW7HcfrxUlA1SQKI8a9j/Us0vW3vcb4t1S8dh5FsD5bz19s1\njJjQ0+L2lauvfVQ2kM+k8Dgw1cy2N7Mq4JPAzJwyM4HPhP8/BtzXa3sCJNfPc8UdJu6kreH7SPyO\nPZLkwBjnOnaPZ4JjSA4q8Qwy7tzx+nl300wnoXS5dONpvP4Zz8rLw3RH4ne24WGa60guIzXhL29E\n8ewtxj0iTCOeZbamhqkKZWrD/MZksTKMazj+skW8NFZJcrCJDdDNJAfizjD8CHwbBCRn9vEgUhem\nFy/NgG9HiDtgvDYfD3CxERr8wWen8NmEv34OyUFwbfgbHZblBPzpRFP4PpwkoQ4luVxYgV+vQ0jO\n+rcmaVyOw3eQNGDH7agmzP8kkssnw0jaIsamlnW8dl8bvleE5RG3jyEk6zJugy2hDGFcW5Fso7EW\nMjTEHy8TdpC0C9SE5RyTT20YX0yc8fJQbap8PPDHJBD7xe2e8L0zxLs21W9U+B6XU1/be9weK0ku\n94wgqQ3HGONJQqxZVNFzo3FcVi0kiSEuq7HdlO1rH5UNWF/H4M0audnhwE/xq/oa59yPzew8oME5\nN9PMhgLXA9PxNYRPxobpntTvVe8aZjV03zM2YjWRXBaqJjloxe7xzDSeFQ0lOYOJi6M9Zxw93bHQ\n150NuvtIdx/p7iPdfVQAzGyWc66+z3L5TAr5UF9f7xoaekgKIiLSrf4mBf2CSkREuigpiIhIFyUF\nERHpoqQgIiJdlBRERKSLkoKIiHRRUhARkS5KCiIi0qXofrxmZkvwz97MWny2pWhZRFoOCS2LRKEs\ni+2cc+P6KlR0SaFQmFlDf34dWAq0LDwth4SWRaLYloUuH4mISBclBRER6aKksOmuyjqAAqJl4Wk5\nJLQsEkW1LNSmICIiXVRTEBGRLkoKm8nMzjIzZ2bdvfepJJjZJWb2opk9bWa3m9nIrGMaaGZ2qJm9\nZGZzzOzsrOPJiplNNrP7zewFM3vOzE7POqasmVm5mT1hZn/JOpb+UFLYDGY2GfgA/t1fpeweYDfn\n3B7Af4DvZBzPgDKzcmAGcBgwDTjezKZlG1Vm2oFvOOd2BfYDvlLCyyI6HXgh6yD6S0lh81wOfIvk\nJZ4lyTl3t3MuvljxUfwLKUvJPsAc59xc51wrcCNwdMYxZcI5t8g5Nzv8vwZ/MJyYbVTZMbNJwIeB\n/806lv5SUthEZnYU8IZz7qmsYykwJwF/yzqIATYReD31fQElfCCMzGwK/v3rj2UbSaZ+ij9x7Mw6\nkP6qyDqAQmZm/4/kNfFp5wLnAB8c2Iiy09uycM7dEcqci7988IeBjK0AWDfdSrr2aGbDgFuBM5xz\nq7OOJwtmdgSw2Dk3y8zek3U8/aWk0Avn3CHddTez3YHtgafMDPzlktlmto9z7s0BDHHA9LQsIjP7\nDHAE8H5Xevc5LwAmp75PAhZmFEvmzKwSnxD+4Jy7Let4MnQgcJSZHQ4MBerM7PfOuRMyjqtX+p3C\nFmBm84B651whPPRqwJnZocD/AO92zi3JOp6BZmYV+Ab29wNvAI8Dn3LOPZdpYBkwf5Z0HbDcOXdG\n1vEUilBTOMs5d0TWsfRFbQqyJfwCGA7cY2ZPmtmVWQc0kEIj+2nAXfiG1ZtLMSEEBwInAu8L28KT\n4UxZioRqCiIi0kU1BRER6aKkICIiXZQURESki5KCiIh0UVIQEZEuSgoiItJFSUFERLroMRcimyg8\n32doH8WWleBjP6SI6cdrIpvIzK4GTu6j2LhSffyJFCclBZFNZGbvBB4EXgMOBxq7KaaaghQVtSmI\nbKLwMpljgJ3xb15b4ZxbmvPXlRDM7Dwze8bM/mNmp2QVt0hvlBSkJJnZRDP7iZn90czONrOvhEc+\nbxTn3D3A5/Bv1/pVL9P7EP6FM3sCxwIf6abM58zsajOrNLMKM7vHzHbc2JhENoeSgpQcM9sG2B/4\nAXAlUA/c7pxr25TxOef+AHwb+IKZfa+HYkcBvwUq8U9UvbWbMvcCU4FDwpNXHwambEpMIptKdx9J\nyXHOLQRuATCz0cAPQ7cuZvYw/nHguc5yzv2/bsZ5iZlNAH5oZgucc9fkFNkL/56FZcA84MxuxjHf\nzB4C3m5mncCrzrl7N3oGRTaDGpqlJJnZnsAF4esfnXPXb4FxjgdeAV4F9nDOdYbuZcB859wkM6sG\nfg38xzl3vpn9yDn33VDOQkwHASc6514N3bvKiOSbagpSqlYCf3fO/ay7nhtbUzCzGmAmsA44KiaE\n4G3AywDOuSYz+ycwPiSRijD83sA04N/4t/jFhNBVRmQgaGOTkmNmk4FjnHP/01MZ59xBGzG+MuAP\nwO7Ae51zc3OKTAeGmFk5fp/7FPC10P1JMzsEaHLOXWdmWwO/NDMLdy5NB57ciNkT2SxqaJaSEt6V\ne3f4f+dU9102Y7SXA0fjL/k82k3/PYFq/KWlfwLXOeeeCt2fBA7BJwqcc28Bs4GbQntHLCMyIFRT\nkJLinHsgvDP4BOB2M2sGngIu3pTxmdnX8Gf933LO3dJDsen4hPFsTved8JeV/huwVIwfTo0/lhEZ\nEGpoFtlEZnY0cBtwF/D1HorNB14Ctg+3mYoUNCUFkU1kZk/j2xF6817n3AMDEI7IFqGkICIiXdTQ\nLCIiXZQURESki5KCiIh0UVIQEZEuSgoiItJFSUFERLooKYiISBclBRER6fL/AReu9dpeu3q2AAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1411ed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xcoord = X_test.dot(model.coef_.T)\n",
    "plt.scatter(xcoord, y_test,color=[1,0,1,.05])\n",
    "plt.scatter(-xcoord, 1-y_test,color=[1,0,1,.05])\n",
    "plt.xlabel('${\\cal Z}=\\sum \\\\beta_i {\\cal X}_i$')\n",
    "plt.ylabel('Outcome')\n",
    "x=np.linspace(-10,10,100)\n",
    "plt.plot(x,logit(x),'r--')\n",
    "plt.xlim(-5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [221, 265]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5dba9120e7b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predPythag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \"\"\"\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [221, 265]"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test,np.round(y_predPythag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 43,  37],\n",
       "       [ 23, 118]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75113122171945701"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "rf.fit(X_train,y_train)\n",
    "pred=rf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-0636f2d161fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Log reg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pythag'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scatter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resDF' is not defined"
     ]
    }
   ],
   "source": [
    "resDF.plot(x='Log reg',y='Pythag',kind='scatter')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with teams split by k-means and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 613\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.68515497553\n",
      "10-fold cross validation average accuracy: 0.669\n",
      "01 281\n",
      "Accuracy of logistic regression classifier on test set: 0.84\n",
      "Accuracy using pythagorean win expectation:  0.79359430605\n",
      "10-fold cross validation average accuracy: 0.830\n",
      "02 940\n",
      "Accuracy of logistic regression classifier on test set: 0.77\n",
      "Accuracy using pythagorean win expectation:  0.76170212766\n",
      "10-fold cross validation average accuracy: 0.754\n",
      "11 388\n",
      "Accuracy of logistic regression classifier on test set: 0.65\n",
      "Accuracy using pythagorean win expectation:  0.682989690722\n",
      "10-fold cross validation average accuracy: 0.669\n",
      "12 287\n",
      "Accuracy of logistic regression classifier on test set: 0.92\n",
      "Accuracy using pythagorean win expectation:  0.91637630662\n",
      "10-fold cross validation average accuracy: 0.922\n",
      "22 530\n",
      "Accuracy of logistic regression classifier on test set: 0.70\n",
      "Accuracy using pythagorean win expectation:  0.694339622642\n",
      "10-fold cross validation average accuracy: 0.687\n",
      "\n",
      "0.737416863787\n",
      "0.742020401448\n",
      "00 573\n",
      "Accuracy of logistic regression classifier on test set: 0.72\n",
      "Accuracy using pythagorean win expectation:  0.713787085515\n",
      "10-fold cross validation average accuracy: 0.651\n",
      "01 282\n",
      "Accuracy of logistic regression classifier on test set: 0.81\n",
      "Accuracy using pythagorean win expectation:  0.808510638298\n",
      "10-fold cross validation average accuracy: 0.815\n",
      "02 863\n",
      "Accuracy of logistic regression classifier on test set: 0.78\n",
      "Accuracy using pythagorean win expectation:  0.800695249131\n",
      "10-fold cross validation average accuracy: 0.778\n",
      "11 408\n",
      "Accuracy of logistic regression classifier on test set: 0.65\n",
      "Accuracy using pythagorean win expectation:  0.671568627451\n",
      "10-fold cross validation average accuracy: 0.670\n",
      "12 380\n",
      "Accuracy of logistic regression classifier on test set: 0.91\n",
      "Accuracy using pythagorean win expectation:  0.910526315789\n",
      "10-fold cross validation average accuracy: 0.920\n",
      "22 526\n",
      "Accuracy of logistic regression classifier on test set: 0.63\n",
      "Accuracy using pythagorean win expectation:  0.665399239544\n",
      "10-fold cross validation average accuracy: 0.642\n",
      "\n",
      "0.737129063522\n",
      "0.757915567282\n",
      "00 309\n",
      "Accuracy of logistic regression classifier on test set: 0.65\n",
      "Accuracy using pythagorean win expectation:  0.669902912621\n",
      "10-fold cross validation average accuracy: 0.630\n",
      "01 840\n",
      "Accuracy of logistic regression classifier on test set: 0.77\n",
      "Accuracy using pythagorean win expectation:  0.789285714286\n",
      "10-fold cross validation average accuracy: 0.771\n",
      "02 282\n",
      "Accuracy of logistic regression classifier on test set: 0.91\n",
      "Accuracy using pythagorean win expectation:  0.918439716312\n",
      "10-fold cross validation average accuracy: 0.899\n",
      "11 644\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.680124223602\n",
      "10-fold cross validation average accuracy: 0.662\n",
      "12 390\n",
      "Accuracy of logistic regression classifier on test set: 0.79\n",
      "Accuracy using pythagorean win expectation:  0.776923076923\n",
      "10-fold cross validation average accuracy: 0.774\n",
      "22 536\n",
      "Accuracy of logistic regression classifier on test set: 0.68\n",
      "Accuracy using pythagorean win expectation:  0.67723880597\n",
      "10-fold cross validation average accuracy: 0.693\n",
      "\n",
      "0.731521485249\n",
      "0.744085304898\n",
      "00 586\n",
      "Accuracy of logistic regression classifier on test set: 0.69\n",
      "Accuracy using pythagorean win expectation:  0.692832764505\n",
      "10-fold cross validation average accuracy: 0.699\n",
      "01 287\n",
      "Accuracy of logistic regression classifier on test set: 0.82\n",
      "Accuracy using pythagorean win expectation:  0.794425087108\n",
      "10-fold cross validation average accuracy: 0.801\n",
      "02 442\n",
      "Accuracy of logistic regression classifier on test set: 0.85\n",
      "Accuracy using pythagorean win expectation:  0.864253393665\n",
      "10-fold cross validation average accuracy: 0.867\n",
      "11 345\n",
      "Accuracy of logistic regression classifier on test set: 0.64\n",
      "Accuracy using pythagorean win expectation:  0.649275362319\n",
      "10-fold cross validation average accuracy: 0.644\n",
      "12 802\n",
      "Accuracy of logistic regression classifier on test set: 0.79\n",
      "Accuracy using pythagorean win expectation:  0.779301745636\n",
      "10-fold cross validation average accuracy: 0.788\n",
      "22 543\n",
      "Accuracy of logistic regression classifier on test set: 0.69\n",
      "Accuracy using pythagorean win expectation:  0.664825046041\n",
      "10-fold cross validation average accuracy: 0.681\n",
      "\n",
      "0.74747637304\n",
      "0.740765391015\n",
      "00 532\n",
      "Accuracy of logistic regression classifier on test set: 0.66\n",
      "Accuracy using pythagorean win expectation:  0.65037593985\n",
      "10-fold cross validation average accuracy: 0.698\n",
      "01 341\n",
      "Accuracy of logistic regression classifier on test set: 0.91\n",
      "Accuracy using pythagorean win expectation:  0.91788856305\n",
      "10-fold cross validation average accuracy: 0.913\n",
      "02 296\n",
      "Accuracy of logistic regression classifier on test set: 0.77\n",
      "Accuracy using pythagorean win expectation:  0.787162162162\n",
      "10-fold cross validation average accuracy: 0.790\n",
      "11 532\n",
      "Accuracy of logistic regression classifier on test set: 0.66\n",
      "Accuracy using pythagorean win expectation:  0.646616541353\n",
      "10-fold cross validation average accuracy: 0.685\n",
      "12 810\n",
      "Accuracy of logistic regression classifier on test set: 0.80\n",
      "Accuracy using pythagorean win expectation:  0.802469135802\n",
      "10-fold cross validation average accuracy: 0.783\n",
      "22 471\n",
      "Accuracy of logistic regression classifier on test set: 0.70\n",
      "Accuracy using pythagorean win expectation:  0.709129511677\n",
      "10-fold cross validation average accuracy: 0.658\n",
      "\n",
      "0.746160913262\n",
      "0.744466800805\n",
      "00 536\n",
      "Accuracy of logistic regression classifier on test set: 0.73\n",
      "Accuracy using pythagorean win expectation:  0.722014925373\n",
      "10-fold cross validation average accuracy: 0.694\n",
      "01 715\n",
      "Accuracy of logistic regression classifier on test set: 0.75\n",
      "Accuracy using pythagorean win expectation:  0.74965034965\n",
      "10-fold cross validation average accuracy: 0.770\n",
      "02 513\n",
      "Accuracy of logistic regression classifier on test set: 0.90\n",
      "Accuracy using pythagorean win expectation:  0.906432748538\n",
      "10-fold cross validation average accuracy: 0.913\n",
      "11 293\n",
      "Accuracy of logistic regression classifier on test set: 0.69\n",
      "Accuracy using pythagorean win expectation:  0.686006825939\n",
      "10-fold cross validation average accuracy: 0.691\n",
      "12 322\n",
      "Accuracy of logistic regression classifier on test set: 0.74\n",
      "Accuracy using pythagorean win expectation:  0.754658385093\n",
      "10-fold cross validation average accuracy: 0.761\n",
      "22 557\n",
      "Accuracy of logistic regression classifier on test set: 0.68\n",
      "Accuracy using pythagorean win expectation:  0.678635547576\n",
      "10-fold cross validation average accuracy: 0.701\n",
      "\n",
      "0.759121806828\n",
      "0.75272479564\n",
      "00 411\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.698296836983\n",
      "10-fold cross validation average accuracy: 0.662\n",
      "01 787\n",
      "Accuracy of logistic regression classifier on test set: 0.79\n",
      "Accuracy using pythagorean win expectation:  0.790343074968\n",
      "10-fold cross validation average accuracy: 0.779\n",
      "02 237\n",
      "Accuracy of logistic regression classifier on test set: 0.94\n",
      "Accuracy using pythagorean win expectation:  0.940928270042\n",
      "10-fold cross validation average accuracy: 0.936\n",
      "11 663\n",
      "Accuracy of logistic regression classifier on test set: 0.64\n",
      "Accuracy using pythagorean win expectation:  0.613876319759\n",
      "10-fold cross validation average accuracy: 0.661\n",
      "12 468\n",
      "Accuracy of logistic regression classifier on test set: 0.80\n",
      "Accuracy using pythagorean win expectation:  0.801282051282\n",
      "10-fold cross validation average accuracy: 0.812\n",
      "22 357\n",
      "Accuracy of logistic regression classifier on test set: 0.63\n",
      "Accuracy using pythagorean win expectation:  0.627450980392\n",
      "10-fold cross validation average accuracy: 0.670\n",
      "\n",
      "0.740584422896\n",
      "0.731440301061\n",
      "00 360\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.716666666667\n",
      "10-fold cross validation average accuracy: 0.652\n",
      "01 184\n",
      "Accuracy of logistic regression classifier on test set: 0.98\n",
      "Accuracy using pythagorean win expectation:  0.994565217391\n",
      "10-fold cross validation average accuracy: 0.960\n",
      "02 501\n",
      "Accuracy of logistic regression classifier on test set: 0.84\n",
      "Accuracy using pythagorean win expectation:  0.834331337325\n",
      "10-fold cross validation average accuracy: 0.823\n",
      "11 368\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.627\n",
      "12 638\n",
      "Accuracy of logistic regression classifier on test set: 0.82\n",
      "Accuracy using pythagorean win expectation:  0.815047021944\n",
      "10-fold cross validation average accuracy: 0.799\n",
      "22 674\n",
      "Accuracy of logistic regression classifier on test set: 0.68\n",
      "Accuracy using pythagorean win expectation:  0.695845697329\n",
      "10-fold cross validation average accuracy: 0.650\n",
      "\n",
      "0.734948243054\n",
      "0.771009174312\n",
      "00 612\n",
      "Accuracy of logistic regression classifier on test set: 0.64\n",
      "Accuracy using pythagorean win expectation:  0.62091503268\n",
      "10-fold cross validation average accuracy: 0.644\n",
      "01 431\n",
      "Accuracy of logistic regression classifier on test set: 0.88\n",
      "Accuracy using pythagorean win expectation:  0.867749419954\n",
      "10-fold cross validation average accuracy: 0.845\n",
      "02 646\n",
      "Accuracy of logistic regression classifier on test set: 0.77\n",
      "Accuracy using pythagorean win expectation:  0.78173374613\n",
      "10-fold cross validation average accuracy: 0.764\n",
      "11 406\n",
      "Accuracy of logistic regression classifier on test set: 0.68\n",
      "Accuracy using pythagorean win expectation:  0.709359605911\n",
      "10-fold cross validation average accuracy: 0.654\n",
      "12 195\n",
      "Accuracy of logistic regression classifier on test set: 0.93\n",
      "Accuracy using pythagorean win expectation:  0.94358974359\n",
      "10-fold cross validation average accuracy: 0.960\n",
      "22 404\n",
      "Accuracy of logistic regression classifier on test set: 0.64\n",
      "Accuracy using pythagorean win expectation:  0.660891089109\n",
      "10-fold cross validation average accuracy: 0.656\n",
      "\n",
      "0.731065819635\n",
      "0.741648106904\n",
      "00 499\n",
      "Accuracy of logistic regression classifier on test set: 0.68\n",
      "Accuracy using pythagorean win expectation:  0.689378757515\n",
      "10-fold cross validation average accuracy: 0.688\n",
      "01 337\n",
      "Accuracy of logistic regression classifier on test set: 0.76\n",
      "Accuracy using pythagorean win expectation:  0.756676557864\n",
      "10-fold cross validation average accuracy: 0.761\n",
      "02 312\n",
      "Accuracy of logistic regression classifier on test set: 0.94\n",
      "Accuracy using pythagorean win expectation:  0.942307692308\n",
      "10-fold cross validation average accuracy: 0.937\n",
      "11 362\n",
      "Accuracy of logistic regression classifier on test set: 0.65\n",
      "Accuracy using pythagorean win expectation:  0.657458563536\n",
      "10-fold cross validation average accuracy: 0.610\n",
      "12 701\n",
      "Accuracy of logistic regression classifier on test set: 0.76\n",
      "Accuracy using pythagorean win expectation:  0.760342368046\n",
      "10-fold cross validation average accuracy: 0.757\n",
      "22 450\n",
      "Accuracy of logistic regression classifier on test set: 0.64\n",
      "Accuracy using pythagorean win expectation:  0.673333333333\n",
      "10-fold cross validation average accuracy: 0.656\n",
      "\n",
      "0.728378703589\n",
      "0.739195791056\n",
      "00 326\n",
      "Accuracy of logistic regression classifier on test set: 0.63\n",
      "Accuracy using pythagorean win expectation:  0.684049079755\n",
      "10-fold cross validation average accuracy: 0.612\n",
      "01 655\n",
      "Accuracy of logistic regression classifier on test set: 0.79\n",
      "Accuracy using pythagorean win expectation:  0.795419847328\n",
      "10-fold cross validation average accuracy: 0.757\n",
      "02 208\n",
      "Accuracy of logistic regression classifier on test set: 0.93\n",
      "Accuracy using pythagorean win expectation:  0.932692307692\n",
      "10-fold cross validation average accuracy: 0.928\n",
      "11 533\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.679174484053\n",
      "10-fold cross validation average accuracy: 0.683\n",
      "12 416\n",
      "Accuracy of logistic regression classifier on test set: 0.78\n",
      "Accuracy using pythagorean win expectation:  0.762019230769\n",
      "10-fold cross validation average accuracy: 0.803\n",
      "22 481\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.656964656965\n",
      "10-fold cross validation average accuracy: 0.703\n",
      "\n",
      "0.734598731354\n",
      "0.738067964872\n",
      "00 482\n",
      "Accuracy of logistic regression classifier on test set: 0.69\n",
      "Accuracy using pythagorean win expectation:  0.676348547718\n",
      "10-fold cross validation average accuracy: 0.661\n",
      "01 517\n",
      "Accuracy of logistic regression classifier on test set: 0.76\n",
      "Accuracy using pythagorean win expectation:  0.762088974855\n",
      "10-fold cross validation average accuracy: 0.779\n",
      "02 351\n",
      "Accuracy of logistic regression classifier on test set: 0.77\n",
      "Accuracy using pythagorean win expectation:  0.786324786325\n",
      "10-fold cross validation average accuracy: 0.766\n",
      "11 355\n",
      "Accuracy of logistic regression classifier on test set: 0.73\n",
      "Accuracy using pythagorean win expectation:  0.732394366197\n",
      "10-fold cross validation average accuracy: 0.683\n",
      "12 280\n",
      "Accuracy of logistic regression classifier on test set: 0.94\n",
      "Accuracy using pythagorean win expectation:  0.946428571429\n",
      "10-fold cross validation average accuracy: 0.925\n",
      "22 530\n",
      "Accuracy of logistic regression classifier on test set: 0.70\n",
      "Accuracy using pythagorean win expectation:  0.705660377358\n",
      "10-fold cross validation average accuracy: 0.670\n",
      "\n",
      "0.734261502166\n",
      "0.753479125249\n",
      "00 571\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.661996497373\n",
      "10-fold cross validation average accuracy: 0.625\n",
      "01 518\n",
      "Accuracy of logistic regression classifier on test set: 0.75\n",
      "Accuracy using pythagorean win expectation:  0.764478764479\n",
      "10-fold cross validation average accuracy: 0.774\n",
      "02 562\n",
      "Accuracy of logistic regression classifier on test set: 0.83\n",
      "Accuracy using pythagorean win expectation:  0.834519572954\n",
      "10-fold cross validation average accuracy: 0.825\n",
      "11 185\n",
      "Accuracy of logistic regression classifier on test set: 0.70\n",
      "Accuracy using pythagorean win expectation:  0.708108108108\n",
      "10-fold cross validation average accuracy: 0.674\n",
      "12 139\n",
      "Accuracy of logistic regression classifier on test set: 0.96\n",
      "Accuracy using pythagorean win expectation:  0.956834532374\n",
      "10-fold cross validation average accuracy: 0.932\n",
      "22 537\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.683426443203\n",
      "10-fold cross validation average accuracy: 0.673\n",
      "\n",
      "0.731158697519\n",
      "0.74601910828\n",
      "00 259\n",
      "Accuracy of logistic regression classifier on test set: 0.63\n",
      "Accuracy using pythagorean win expectation:  0.644787644788\n",
      "10-fold cross validation average accuracy: 0.669\n",
      "01 581\n",
      "Accuracy of logistic regression classifier on test set: 0.81\n",
      "Accuracy using pythagorean win expectation:  0.822719449225\n",
      "10-fold cross validation average accuracy: 0.837\n",
      "02 95\n",
      "Accuracy of logistic regression classifier on test set: 0.96\n",
      "Accuracy using pythagorean win expectation:  0.989473684211\n",
      "10-fold cross validation average accuracy: 0.918\n",
      "11 706\n",
      "Accuracy of logistic regression classifier on test set: 0.66\n",
      "Accuracy using pythagorean win expectation:  0.661473087819\n",
      "10-fold cross validation average accuracy: 0.687\n",
      "12 437\n",
      "Accuracy of logistic regression classifier on test set: 0.84\n",
      "Accuracy using pythagorean win expectation:  0.844393592677\n",
      "10-fold cross validation average accuracy: 0.815\n",
      "22 415\n",
      "Accuracy of logistic regression classifier on test set: 0.67\n",
      "Accuracy using pythagorean win expectation:  0.698795180723\n",
      "10-fold cross validation average accuracy: 0.707\n",
      "\n",
      "0.754569502728\n",
      "0.748094665062\n"
     ]
    }
   ],
   "source": [
    "resultList=[]\n",
    "for yr in np.arange(2017,2003,-1):\n",
    "    year=str(yr)\n",
    "    teamType=pd.read_csv('data/team_type_'+year+'.csv')\n",
    "    teamTypeDict={}\n",
    "    for r in teamType.values:\n",
    "        teamTypeDict[r[0]]=r[1]\n",
    "\n",
    "    df=pd.read_csv('data/games/all_games_'+year+'.csv',index_col=0).dropna(axis=1)\n",
    "    # df=pd.read_csv('data/games/tourn_games_2016.csv',index_col=0)\n",
    "    # y=df['outcome']\n",
    "    dropLabels=['School_1','Conf_1','wpct_1','Rank_1','WL_1','sched_url_1',\\\n",
    "                'School_2','Conf_2','wpct_2','Rank_2','WL_2','sched_url_2', 'outcome']\n",
    "\n",
    "    y=df['outcome']\n",
    "\n",
    "\n",
    "    types=[]\n",
    "    for r in df.itertuples():\n",
    "\n",
    "        t1=teamTypeDict[r.School_1]\n",
    "        t2=teamTypeDict[r.School_2]\n",
    "\n",
    "        types.append(str(min(t1,t2))+str(max(t1,t2)))\n",
    "\n",
    "    df['types']=types\n",
    "\n",
    "    runsum=0\n",
    "    numsum=0\n",
    "    pythsum=0\n",
    "\n",
    "    nlab=3\n",
    "    for t1lab in range(nlab):\n",
    "        for t2lab in np.arange(t1lab,nlab):\n",
    "            lab = str(t1lab)+str(t2lab)\n",
    "\n",
    "            dfSel = df[(df.types==lab)]\n",
    "            dropLabels.append('types')\n",
    "\n",
    "            X=dfSel.drop(dropLabels,axis=1)\n",
    "            y=dfSel['outcome']\n",
    "\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "            logreg = LogisticRegression()\n",
    "            logreg.fit(X_train, y_train)\n",
    "\n",
    "            y_pred=logreg.predict(X_test)\n",
    "            print(lab,len(y_pred))\n",
    "            print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "            y_predPythag=pythagGame(X_test)\n",
    "\n",
    "            print('Accuracy using pythagorean win expectation: ',(np.round(y_predPythag)==y_test).sum()/len(y_test))\n",
    "\n",
    "\n",
    "            kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "            modelCV = LogisticRegression()\n",
    "            scoring = 'accuracy'\n",
    "            results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "            print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))    \n",
    "\n",
    "            runsum+= len(y_pred) * results.mean() #logreg.score(X_test, y_test)\n",
    "            numsum+= len(y_pred)\n",
    "            pythsum+= len(y_pred) *(np.round(y_predPythag)==y_test).sum()/len(y_test)\n",
    "\n",
    "\n",
    "\n",
    "    print ()\n",
    "    print (runsum/numsum)\n",
    "    print (pythsum/numsum)\n",
    "    \n",
    "    resultList.append([year,(runsum/numsum),pythsum/numsum])\n",
    "    \n",
    "resDFKM=pd.DataFrame(resultList,columns=['year','Log reg','Pythag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year       1.440858e+54\n",
       "Log reg    7.391709e-01\n",
       "Pythag     7.464952e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resDFKM.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.578\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "modelCV = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.70\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "# logreg = LogisticRegression(C=1,penalty='l1',tol=0.1)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred=logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['pythag']=pythagGame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using pythagorean win expectation:  0.739459815547\n"
     ]
    }
   ],
   "source": [
    "y_predPythag=pythagGame(X_test)\n",
    "\n",
    "print('Accuracy using pythagorean win expectation: ',(np.round(y_predPythag)==y_test).sum()/len(y_test))\n",
    "# print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
